{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- label smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more configs for training are defined later\n",
    "TRAINING_DIRECTORY = '../data/preprocessed_stories'\n",
    "EXTENSION = '.clean'\n",
    "N_TRAIN_FILES = 100_000\n",
    "N_TEST_FILES = 500\n",
    "# TOKENS_PER_BATCH = 4096\n",
    "TOKENS_PER_BATCH = 1_000\n",
    "BPE_MODEL_FILE = 'summarizer_10000.model'\n",
    "BPE_VOCAB_FILE = 'summarizer_10000.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # show tensor2tensor hparams for summarization for reference\n",
    "# import tensor2tensor.models.transformer\n",
    "# from tensor2tensor.utils.registry import hparams\n",
    "# params = hparams('transformer_prepend')()\n",
    "# for k, v in sorted(vars(params).items(), key=lambda tup: tup[0]):\n",
    "#     if not k.startswith('_') and not callable(v):\n",
    "#         print(f'{k}={v!r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/preprocessed_stories/8bea156c50b9bb04ef1804a13971c381e63b790f.clean',\n",
       " '../data/preprocessed_stories/96f71e32fad9bfef59c4a67b021609cf86b126de.clean',\n",
       " '../data/preprocessed_stories/50a945a090973a747082435b6f4bfd1da7922ad6.clean',\n",
       " '../data/preprocessed_stories/0e2569c383c66c3491f16029af147019d79a2480.clean',\n",
       " '../data/preprocessed_stories/17c1d1ff679615f250f545750a3fa7feddc9a9ca.clean',\n",
       " '../data/preprocessed_stories/7471e1359d1b9e0440d948ee116089b109d005c3.clean',\n",
       " '../data/preprocessed_stories/b7470294d56d294e4fd9801f190ae92352e1216a.clean',\n",
       " '../data/preprocessed_stories/021d78038eef6d680537762a51963f514059ea97.clean',\n",
       " '../data/preprocessed_stories/debcabe9677c446e3fbb8851f225cb30d38beea6.clean',\n",
       " '../data/preprocessed_stories/b2fcb5fce5937b69c882a09151ba83c084fa4ad4.clean']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = glob.glob('%s/*%s' % (TRAINING_DIRECTORY, EXTENSION))\n",
    "print(len(FILES))\n",
    "FILES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = FILES[:N_TRAIN_FILES]\n",
    "TEST_FILES = FILES[N_TRAIN_FILES:N_TRAIN_FILES+N_TEST_FILES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define batch generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "\n",
    "class BytePairEncoder:\n",
    "    def __init__(self, vocab_size, model_name, *, model_file=None, vocab_file=None,\n",
    "                 training_file=None, processor=None, **kwargs):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model_name = model_name\n",
    "        self.training_file = training_file\n",
    "        self.model_file = f'{self.model_name}.model' if model_file is None else model_file\n",
    "        self.vocab_file = f'{self.model_name}.vocab' if vocab_file is None else vocab_file\n",
    "        if processor is None:\n",
    "            if training_file is None:\n",
    "                raise ValueError('training_file cannot be None when processor is also None.')\n",
    "            processor = self._fit(input=training_file, vocab_size=vocab_size,\n",
    "                                  model_prefix=model_name, model_type='bpe',\n",
    "                                  **kwargs)\n",
    "        self.processor = processor\n",
    "        \n",
    "    def encode(self, text):\n",
    "        return np.array(self.processor.EncodeAsIds(text))\n",
    "    \n",
    "    def encode_as_pieces(self, text):\n",
    "        return self.processor.EncodeAsPieces(text)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.processor.DecodeIds(ids.tolist())\n",
    "    \n",
    "    def decode_pieces(self, pieces):\n",
    "        return self.processor.DecodePieces(pieces)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, model_file, vocab_file):\n",
    "        model_name = model_file.partition('.')[0]\n",
    "        processor = cls._load_model(model_file)\n",
    "        for vocab_size, _ in enumerate(open(vocab_file), start=1): pass\n",
    "        return cls(vocab_size=vocab_size, model_name=model_name, processor=processor,\n",
    "                   model_file=model_file, vocab_file=vocab_file)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_model(filename):\n",
    "        processor = spm.SentencePieceProcessor()\n",
    "        processor.Load(filename)\n",
    "        return processor\n",
    "        \n",
    "    def _fit(self, **kwargs):\n",
    "        params = ' '.join([f'--{k}={v}' for k, v in kwargs.items()])\n",
    "        spm.SentencePieceTrainer.Train(params)\n",
    "        processor = self._load_model(self.model_file)\n",
    "        return processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function - decoding an unkown token breaks sentencepiece\n",
    "def decode(arr, pad_token, decoder):\n",
    "    valid_tokens = iter(arr[arr != pad_token])\n",
    "    output = []\n",
    "    for pad in (arr == pad_token):\n",
    "        output.append('<pad>' if pad else decoder(np.array([next(valid_tokens)])))\n",
    "    print(len(output))\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained in byte-pair-encoding\n",
    "TOKENIZER = BytePairEncoder.from_files(BPE_MODEL_FILE, BPE_VOCAB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENIZER.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingExample:\n",
    "    \"\"\"Simple container to keep track of training data. Useful for debugging.\"\"\"\n",
    "    def __init__(self, item, context_text, target_text, context_tokens,\n",
    "                 target_tokens, filename):\n",
    "        self.item = item\n",
    "        self.context_text = context_text\n",
    "        self.target_text = target_text\n",
    "        self.context_tokens = context_tokens\n",
    "        self.target_tokens = target_tokens\n",
    "        self.filename = filename\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.context_tokens) + len(self.target_tokens)\n",
    "\n",
    "def load_files(files, encoder):\n",
    "    \"\"\"Load and tokenize files.\"\"\"\n",
    "    training_examples = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            context_text, target_text = f.read().split('\\t')\n",
    "        context_tokens = encoder(context_text)\n",
    "        target_tokens = encoder(target_text)\n",
    "        example = TrainingExample(file, context_text, target_text,\n",
    "                                  context_tokens, target_tokens,\n",
    "                                  file)\n",
    "        training_examples.append(example)\n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a478557b51c49218b2851243e0a1e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 27s, sys: 3.23 s, total: 3min 31s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "TRAINING_EXAMPLES = load_files(tqdm(TRAIN_FILES), TOKENIZER.encode)\n",
    "# sort files by number of tokens to reduce padding\n",
    "TRAINING_EXAMPLES = sorted(TRAINING_EXAMPLES, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 4263, 913.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAINING_EXAMPLES[0]), len(TRAINING_EXAMPLES[-1]), np.median([len(example) for example in TRAINING_EXAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "looky = iter(TRAINING_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/preprocessed_stories/86bd905861391cbd3a98de15c83768b6d1400304.clean\n",
      "CONTEXT TEXT\n",
      "Congressman Jared Polis\n",
      "\n",
      "(D) Colorado: District 02\n",
      "\n",
      "Congressman Jason Chaffetz\n",
      "\n",
      "(R) Utah: District 03\n",
      "\n",
      "TARGET TEXT\n",
      "Two freshman representatives document their experience for CNN. Rep. Jared Polis is a Democrat representing Colorado's Second district.\n",
      "\n",
      "CONTEXT TOKENS (DECODED)\n",
      "Congressman Jared Polis (D) Colorado: District 02 Congressman Jason Chaffetz (R) Utah: District 03\n",
      "\n",
      "TARGET TOKENS (DECODED)\n",
      "Two freshman representatives document their experience for CNN. Rep. Jared Polis is a Democrat representing Colorado's Second district.\n"
     ]
    }
   ],
   "source": [
    "example = next(looky)\n",
    "print(example.filename)\n",
    "print('CONTEXT TEXT')\n",
    "print(example.context_text)\n",
    "print('\\nTARGET TEXT')\n",
    "print(example.target_text)\n",
    "print('\\nCONTEXT TOKENS (DECODED)')\n",
    "print(TOKENIZER.decode(example.context_tokens))\n",
    "print('\\nTARGET TOKENS (DECODED)')\n",
    "print(TOKENIZER.decode(example.target_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data import BaseBatchGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class SummaryBatchGenerator(BaseBatchGenerator):\n",
    "    def __init__(self, max_context_len=None, max_target_len=None, pad_token=0,\n",
    "                 bos_token=1, eos_token=2, prepend=False):\n",
    "        self.max_context_len = max_context_len\n",
    "        self.max_target_len = max_target_len\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.pad_token = pad_token\n",
    "        self.prepend = prepend\n",
    "\n",
    "    def generate_steps(self, item):\n",
    "        example = item  # alias\n",
    "        if self.max_target_len is not None \\\n",
    "                and len(example.target_tokens) > self.max_target_len:\n",
    "            training_step = []\n",
    "        else:\n",
    "            # get encoder tokens.\n",
    "            if self.max_context_len is not None:\n",
    "                encoder_tokens = example.context_tokens[:self.max_context_len]\n",
    "            else:\n",
    "                encoder_tokens = example.context_tokens\n",
    "            # get decoder tokens.\n",
    "            # start with a pad to account for offsetting the decoder input from\n",
    "            # the output tokens\n",
    "            decoder_tokens = np.array([self.pad_token])\n",
    "            if self.prepend:\n",
    "                decoder_tokens = np.append(decoder_tokens, example.context_tokens)\n",
    "                decoder_tokens = np.append(decoder_tokens, self.eos_token)\n",
    "            decoder_tokens = np.append(decoder_tokens, example.target_tokens)\n",
    "            decoder_tokens = np.append(decoder_tokens, self.eos_token)\n",
    "            training_step = [(encoder_tokens, decoder_tokens, len(example))]\n",
    "        return training_step\n",
    "\n",
    "    def generate_batches(self, steps, batch_size):\n",
    "        batches = []\n",
    "        min_batch_size = 0.95 * batch_size\n",
    "        max_batch_size = 1.05 * batch_size\n",
    "        step_sizes = [size for _, _, size in steps]\n",
    "        current_batch_x1s = []\n",
    "        current_batch_x2s = []\n",
    "        items = enumerate(zip(steps, step_sizes, step_sizes[1:]))\n",
    "        max_used_i = -1\n",
    "        for i, (step, step_size, next_step_size) in items:\n",
    "            if step_size > max_batch_size:\n",
    "                continue\n",
    "            encoder_tokens, decoder_tokens, _ = step\n",
    "            current_batch_x1s.append(encoder_tokens)\n",
    "            current_batch_x2s.append(decoder_tokens)\n",
    "            next_batch_size = (len(current_batch_x1s) + 1) * next_step_size  # account for padding\n",
    "            if next_batch_size > max_batch_size:\n",
    "                max_used_i = i\n",
    "                x1 = pad_sequences(current_batch_x1s, value=self.pad_token, padding='post')\n",
    "                x2 = pad_sequences(current_batch_x2s, value=self.pad_token, padding='post')\n",
    "                X = [x1, x2[:,:-1]]\n",
    "                y = x2[:,1:]\n",
    "                batches.append((X, y))\n",
    "                current_batch_x1s, current_batch_x2s = [], []\n",
    "            # if there aren't enough steps left to create a full sized batch\n",
    "            # then break, the leftover steps will be added to the next call\n",
    "            # to generate_batches()\n",
    "            if sum(step_sizes[i+1:]) < batch_size:\n",
    "                break\n",
    "        return (batches, steps[max_used_i+1:]) if max_used_i >= 0 else (batches, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_GENERATOR = SummaryBatchGenerator(pad_token=TOKENIZER.vocab_size, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_generator = BATCH_GENERATOR.generate_epoch(TRAINING_EXAMPLES, batch_size=TOKENS_PER_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 43s, sys: 556 ms, total: 2min 43s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%time epoch = list(epoch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61310, 100000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x1.shape[0] for (x1, x2), y in epoch), len(TRAINING_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOD: if we skip a training example because it is too large or if steps\n",
    "#       are \"leftover\" because they aren't big enough for a batch this will fail\n",
    "#       \n",
    "# assert sum(x1.shape[0] for (x1, _), _ in epoch) == len(TRAINING_EXAMPLES), \\\n",
    "#    'number of steps in batch does not equal number of examples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_training_steps(x1, x2, y):\n",
    "    print('ENCODER INPUT')\n",
    "    print(decode(x1, 10_000, TOKENIZER.decode))\n",
    "    print('\\n')\n",
    "    print('DECODER INPUT')\n",
    "    print(decode(x2, 10_000, TOKENIZER.decode))\n",
    "    print('\\n')\n",
    "    print('OUTPUT')\n",
    "    print(decode(y, 10_000, TOKENIZER.decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(epoch)\n",
    "views = (view_training_steps(x1[0], x2[0], y[0]) for (x1, x2), y in epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER INPUT\n",
      "491\n",
      "By Step h C ock ro ft A her d of c ows was spotted mar aud ing through a sleep y village and into residents ' front g ard ens after myster iously esc aping from a field in a quiet S uff olk village . Police had to help round up the L on gh orn ste ers , c attle and cal ves after they sa un tered through the streets of Re y don , near the se as ide resort of South w old , S uff olk , early on Sunday morning . Commun ity nurse Cath y Ryan , 5 7, jumped out of bed after hearing the c ows ' bell owing ' outside her home and managed to co ax them back into a field . C ows were seen str oll ing through the streets of the tiny village Re y don , near South w old , S uff olk , early on Sunday morning The group of L on gh orn ste ers , c attle and cal ves charged through people ' s g ard ens during their str oll She said : ' I am used to w aking up to the d awn ch or us . But I thought I was dream ing when I heard c ows bel l owing outside my bedroom window at 5 am on a Sunday morning . ' The whole her d of c attle , including the L on gh orn ste ers , were running down , heading towards South w old . ' They brief ly stopped to m unch the grass and then turned back and ran .' She added : ' I managed to get them back to the foot p ath leading to their field but needed more hands as there were too many escape rout es . Police round ed up the c ows into a nearby field and said they were still trying to loc ate the owner of the escaped c attle Res ident Cath y Ryan , 5 7, jumped out of bed to try and take the c ows back to their field after hearing them ' bell owing ' outside her home ' E vent ually police back - up arrived and we safely her ded them into a field . It ' s a total mystery how they escaped and thank fully no one was hurt .' A S uff olk Police spokesman said : ' We had a report that a her d of c ows , some with h orn s , had escaped from a field and were in people ' s g ard ens . ' At 6 am they were back in a field , although it was not clear whether it was the right one . We are still trying to loc ate the owner of the c ows .'\n",
      "\n",
      "\n",
      "DECODER INPUT\n",
      "534\n",
      "<pad> By Step h C ock ro ft A her d of c ows was spotted mar aud ing through a sleep y village and into residents ' front g ard ens after myster iously esc aping from a field in a quiet S uff olk village . Police had to help round up the L on gh orn ste ers , c attle and cal ves after they sa un tered through the streets of Re y don , near the se as ide resort of South w old , S uff olk , early on Sunday morning . Commun ity nurse Cath y Ryan , 5 7, jumped out of bed after hearing the c ows ' bell owing ' outside her home and managed to co ax them back into a field . C ows were seen str oll ing through the streets of the tiny village Re y don , near South w old , S uff olk , early on Sunday morning The group of L on gh orn ste ers , c attle and cal ves charged through people ' s g ard ens during their str oll She said : ' I am used to w aking up to the d awn ch or us . But I thought I was dream ing when I heard c ows bel l owing outside my bedroom window at 5 am on a Sunday morning . ' The whole her d of c attle , including the L on gh orn ste ers , were running down , heading towards South w old . ' They brief ly stopped to m unch the grass and then turned back and ran .' She added : ' I managed to get them back to the foot p ath leading to their field but needed more hands as there were too many escape rout es . Police round ed up the c ows into a nearby field and said they were still trying to loc ate the owner of the escaped c attle Res ident Cath y Ryan , 5 7, jumped out of bed to try and take the c ows back to their field after hearing them ' bell owing ' outside her home ' E vent ually police back - up arrived and we safely her ded them into a field . It ' s a total mystery how they escaped and thank fully no one was hurt .' A S uff olk Police spokesman said : ' We had a report that a her d of c ows , some with h orn s , had escaped from a field and were in people ' s g ard ens . ' At 6 am they were back in a field , although it was not clear whether it was the right one . We are still trying to loc ate the owner of the c ows .'  The c ows were spotted in the village of Re y don , near South w old , S uff olk . Res ident Cath y Ryan tried to control her d as they mar ched through g ard ens .\n",
      "\n",
      "\n",
      "OUTPUT\n",
      "534\n",
      "By Step h C ock ro ft A her d of c ows was spotted mar aud ing through a sleep y village and into residents ' front g ard ens after myster iously esc aping from a field in a quiet S uff olk village . Police had to help round up the L on gh orn ste ers , c attle and cal ves after they sa un tered through the streets of Re y don , near the se as ide resort of South w old , S uff olk , early on Sunday morning . Commun ity nurse Cath y Ryan , 5 7, jumped out of bed after hearing the c ows ' bell owing ' outside her home and managed to co ax them back into a field . C ows were seen str oll ing through the streets of the tiny village Re y don , near South w old , S uff olk , early on Sunday morning The group of L on gh orn ste ers , c attle and cal ves charged through people ' s g ard ens during their str oll She said : ' I am used to w aking up to the d awn ch or us . But I thought I was dream ing when I heard c ows bel l owing outside my bedroom window at 5 am on a Sunday morning . ' The whole her d of c attle , including the L on gh orn ste ers , were running down , heading towards South w old . ' They brief ly stopped to m unch the grass and then turned back and ran .' She added : ' I managed to get them back to the foot p ath leading to their field but needed more hands as there were too many escape rout es . Police round ed up the c ows into a nearby field and said they were still trying to loc ate the owner of the escaped c attle Res ident Cath y Ryan , 5 7, jumped out of bed to try and take the c ows back to their field after hearing them ' bell owing ' outside her home ' E vent ually police back - up arrived and we safely her ded them into a field . It ' s a total mystery how they escaped and thank fully no one was hurt .' A S uff olk Police spokesman said : ' We had a report that a her d of c ows , some with h orn s , had escaped from a field and were in people ' s g ard ens . ' At 6 am they were back in a field , although it was not clear whether it was the right one . We are still trying to loc ate the owner of the c ows .'  The c ows were spotted in the village of Re y don , near South w old , S uff olk . Res ident Cath y Ryan tried to control her d as they mar ched through g ard ens . \n"
     ]
    }
   ],
   "source": [
    "next(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 491) (1, 534)\n",
      "(1, 892) (1, 958)\n"
     ]
    }
   ],
   "source": [
    "(x1, x2), y = epoch[0]\n",
    "print(x1.shape, x2.shape)\n",
    "(x1, x2), y = epoch[-1]\n",
    "print(x1.shape, x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 892), (1, 958))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int,\n",
       "             {'x1_tok': 40375872,\n",
       "              'x1_pad': 67117,\n",
       "              'x1_unk': 73742,\n",
       "              'x2_tok': 42721814,\n",
       "              'x2_pad': 61616,\n",
       "              'x2_unk': 76352}),\n",
       " defaultdict(__main__.LazyAverage,\n",
       "             {'x1_avg_seq_len': 703.8401061226015,\n",
       "              'x1_avg_pad': 1.2539842684453413,\n",
       "              'x1_avg_unk': 1.3777628309324963,\n",
       "              'x2_avg_seq_len': 742.9981503278964,\n",
       "              'x2_avg_pad': 1.1512060235786485,\n",
       "              'x2_avg_unk': 1.426526913663285}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "class LazyAverage:\n",
    "    def __init__(self):\n",
    "        self.v = 0\n",
    "        self.n = 0\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        self.v += other\n",
    "        self.n += 1\n",
    "        return self\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.v / self.n)\n",
    "\n",
    "def calc_stats(epoch, pad_token, unkown_token):\n",
    "    stats = collections.defaultdict(int)\n",
    "    averages = collections.defaultdict(LazyAverage)\n",
    "    for (x1, x2), y in epoch:\n",
    "        stats['x1_tok'] += ((x1 != pad_token) & (x1 != unkown_token)).sum()\n",
    "        stats['x1_pad'] += (x1 == pad_token).sum()\n",
    "        stats['x1_unk'] += (x1 == unkown_token).sum()\n",
    "        stats['x2_tok'] += ((x2 != pad_token) & (x2 != unkown_token)).sum()\n",
    "        stats['x2_pad'] += (x2 == pad_token).sum()\n",
    "        stats['x2_unk'] += (x2 == unkown_token).sum()\n",
    "        averages['x1_avg_seq_len'] += x1.shape[-1]\n",
    "        averages['x1_avg_pad'] += (x1 == pad_token).sum()\n",
    "        averages['x1_avg_unk'] += (x1 == unkown_token).sum()\n",
    "        averages['x2_avg_seq_len'] += x2.shape[-1]\n",
    "        averages['x2_avg_pad'] += (x2 == pad_token).sum()\n",
    "        averages['x2_avg_unk'] += (x2 == unkown_token).sum()\n",
    "    return stats, averages\n",
    "calc_stats(epoch, BATCH_GENERATOR.pad_token, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build final training generator\n",
    "now that we're happy with the batch generator create one that goes forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging\n",
    "LAST_ITEM = collections.deque([None], maxlen=1)\n",
    "def generate_forever(items):\n",
    "    while True:\n",
    "        for item in items:\n",
    "            LAST_ITEM.append(item)\n",
    "            yield item\n",
    "        print('exhausted `items`, repeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_GEN = generate_forever(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([None])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAST_ITEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for loss/metrics/callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "# on custom implementation rather than keras see\n",
    "# https://github.com/tensorflow/tensorflow/issues/17150\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                             logits=y_pred)\n",
    "    return entropy\n",
    "\n",
    "def sparse_entropy(y_true, y_pred):\n",
    "    # why do I have to do this?\n",
    "    return K.log(K.exp(sparse_categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "def perplexity(y_true, y_pred):\n",
    "    return K.exp(sparse_categorical_crossentropy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# see\n",
    "# https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/learning_rate.py\n",
    "class LRScheduler:\n",
    "    \"\"\"Stateful learning rate scheduler.\n",
    "    \n",
    "    Useful if training is stopped and then resumed so that scheduling\n",
    "    resumes considering the epoch during which training was interrupted.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, warmup_steps, learning_rate):\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = 1\n",
    "        self.initial_lr = self.lr()\n",
    "\n",
    "    def lr(self, *args):\n",
    "        scalar = 5000 \\\n",
    "               * self.d_model**-0.5 \\\n",
    "               * min(self.epoch * self.warmup_steps**-1.5, self.epoch**-0.5)\n",
    "        self.epoch += 1\n",
    "        return 0.002 * scalar * self.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "VALIDATION_EXAMPLES = load_files(tqdm(TEST_FILES[:1000]), TOKENIZER.encode)\n",
    "# sort files by number of tokens to reduce padding\n",
    "VALIDATION_EXAMPLES = sorted(VALIDATION_EXAMPLES, key=lambda x: len(x))\n",
    "TEST_EPOCH = list(BATCH_GENERATOR.generate_epoch(VALIDATION_EXAMPLES, batch_size=TOKENS_PER_BATCH))\n",
    "TEST_GEN = generate_forever(TEST_EPOCH)\n",
    "N_VALIDATION_STEPS = BATCH_GENERATOR.batches_per_epoch(VALIDATION_EXAMPLES, batch_size=TOKENS_PER_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model architecture\n",
    "N_HEADS = 8\n",
    "N_LAYERS = 6\n",
    "D_MODEL = 64*N_HEADS\n",
    "SENTENCE_LEN = None\n",
    "VOCAB_SIZE = TOKENIZER.vocab_size + 1  # +1 accounts for pad token\n",
    "DROPOUT = 0.1\n",
    "OUTPUT_ACTIVATION = 'linear'  # temporary workaround for keras bug - see above\n",
    "\n",
    "# learning rate\n",
    "WARMUP_STEPS = 32_000\n",
    "LEARNING_RATE = 0.2\n",
    "LEARNING_RATE_SCHEDULER = LRScheduler(D_MODEL, WARMUP_STEPS, LEARNING_RATE)\n",
    "\n",
    "# # optimization\n",
    "# # https://arxiv.org/pdf/1804.00247.pdf\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.98\n",
    "EPSILON = 1e-9\n",
    "OPTIMIZER = adam(lr=LEARNING_RATE_SCHEDULER.initial_lr, beta_1=BETA_1, beta_2=BETA_2, epsilon=EPSILON)\n",
    "METRICS = []\n",
    "LOSS = sparse_entropy\n",
    "\n",
    "# # batch training\n",
    "N_EPOCHS = 30\n",
    "N_TRAIN_STEPS = 10_000\n",
    "CALLBACKS = [LearningRateScheduler(LEARNING_RATE_SCHEDULER.lr),\n",
    "             TensorBoard(log_dir='./logs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1954915588>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "scheduler = LRScheduler(D_MODEL, WARMUP_STEPS, LEARNING_RATE)\n",
    "learning_rates = [scheduler.lr()\n",
    "                  for _ in range(WARMUP_STEPS+20_000)]\n",
    "plt.plot(learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "model = Transformer(\n",
    "    n_heads=N_HEADS,\n",
    "    encoder_layers=N_LAYERS,\n",
    "    decoder_layers=N_LAYERS,\n",
    "    d_model=D_MODEL,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    sequence_len=SENTENCE_LEN,\n",
    "    dropout=DROPOUT,\n",
    "    output_activation=OUTPUT_ACTIVATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_spec (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_spec (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 512)    5120512     encoder_input_spec[0][0]         \n",
      "                                                                 decoder_input_spec[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_1 (Position (None, None, 512)    0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_scalar (Scalar)       (None, None, 512)    0           positional_encoding_1[0][0]      \n",
      "                                                                 positional_encoding_1[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 512)    0           embedding_scalar[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_mha (MultiHeadAt (None, None, 512)    262144      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 512)    0           encoder_layer1_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_residual1 (Add)  (None, None, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_layernorm1 (Laye (None, None, 512)    1024        encoder_layer1_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_ffn1 (Dense)     (None, None, 512)    262656      encoder_layer1_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_ffn2 (Dense)     (None, None, 512)    262656      encoder_layer1_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 512)    0           encoder_layer1_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_residual2 (Add)  (None, None, 512)    0           encoder_layer1_layernorm1[0][0]  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_layernorm2 (Laye (None, None, 512)    1024        encoder_layer1_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_mha (MultiHeadAt (None, None, 512)    262144      encoder_layer1_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 512)    0           encoder_layer2_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_residual1 (Add)  (None, None, 512)    0           encoder_layer1_layernorm2[0][0]  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_layernorm1 (Laye (None, None, 512)    1024        encoder_layer2_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_ffn1 (Dense)     (None, None, 512)    262656      encoder_layer2_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_ffn2 (Dense)     (None, None, 512)    262656      encoder_layer2_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 512)    0           encoder_layer2_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_residual2 (Add)  (None, None, 512)    0           encoder_layer2_layernorm1[0][0]  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_layernorm2 (Laye (None, None, 512)    1024        encoder_layer2_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_mha (MultiHeadAt (None, None, 512)    262144      encoder_layer2_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 512)    0           encoder_layer3_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_residual1 (Add)  (None, None, 512)    0           encoder_layer2_layernorm2[0][0]  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_layernorm1 (Laye (None, None, 512)    1024        encoder_layer3_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_ffn1 (Dense)     (None, None, 512)    262656      encoder_layer3_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_ffn2 (Dense)     (None, None, 512)    262656      encoder_layer3_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 512)    0           encoder_layer3_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_residual2 (Add)  (None, None, 512)    0           encoder_layer3_layernorm1[0][0]  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_layernorm2 (Laye (None, None, 512)    1024        encoder_layer3_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_mha (MultiHeadAt (None, None, 512)    262144      encoder_layer3_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 512)    0           encoder_layer4_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_residual1 (Add)  (None, None, 512)    0           encoder_layer3_layernorm2[0][0]  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_layernorm1 (Laye (None, None, 512)    1024        encoder_layer4_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_ffn1 (Dense)     (None, None, 512)    262656      encoder_layer4_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_ffn2 (Dense)     (None, None, 512)    262656      encoder_layer4_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 512)    0           encoder_layer4_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_residual2 (Add)  (None, None, 512)    0           encoder_layer4_layernorm1[0][0]  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_layernorm2 (Laye (None, None, 512)    1024        encoder_layer4_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_mha (MultiHeadAt (None, None, 512)    262144      encoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 512)    0           encoder_layer5_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_residual1 (Add)  (None, None, 512)    0           encoder_layer4_layernorm2[0][0]  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_layernorm1 (Laye (None, None, 512)    1024        encoder_layer5_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_ffn1 (Dense)     (None, None, 512)    262656      encoder_layer5_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_ffn2 (Dense)     (None, None, 512)    262656      encoder_layer5_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 512)    0           encoder_layer5_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_residual2 (Add)  (None, None, 512)    0           encoder_layer5_layernorm1[0][0]  \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_layernorm2 (Laye (None, None, 512)    1024        encoder_layer5_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_mha (MultiHeadAt (None, None, 512)    262144      encoder_layer5_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 512)    0           encoder_layer6_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_residual1 (Add)  (None, None, 512)    0           encoder_layer5_layernorm2[0][0]  \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_layernorm1 (Laye (None, None, 512)    1024        encoder_layer6_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 512)    0           embedding_scalar[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_ffn1 (Dense)     (None, None, 512)    262656      encoder_layer6_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_mha1 (MultiHeadA (None, None, 512)    262144      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_ffn2 (Dense)     (None, None, 512)    262656      encoder_layer6_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 512)    0           decoder_layer1_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 512)    0           encoder_layer6_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual1 (Add)  (None, None, 512)    0           dropout_2[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_residual2 (Add)  (None, None, 512)    0           encoder_layer6_layernorm1[0][0]  \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm1 (Laye (None, None, 512)    1024        decoder_layer1_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_layernorm2 (Laye (None, None, 512)    1024        encoder_layer6_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_mha2 (MultiHeadA (None, None, 512)    262144      decoder_layer1_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 512)    0           decoder_layer1_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual2 (Add)  (None, None, 512)    0           decoder_layer1_layernorm1[0][0]  \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm2 (Laye (None, None, 512)    1024        decoder_layer1_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_ffn1 (Dense)     (None, None, 512)    262656      decoder_layer1_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_ffn2 (Dense)     (None, None, 512)    262656      decoder_layer1_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 512)    0           decoder_layer1_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual3 (Add)  (None, None, 512)    0           decoder_layer1_layernorm2[0][0]  \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm3 (Laye (None, None, 512)    1024        decoder_layer1_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_mha1 (MultiHeadA (None, None, 512)    262144      decoder_layer1_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 512)    0           decoder_layer2_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual1 (Add)  (None, None, 512)    0           decoder_layer1_layernorm3[0][0]  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm1 (Laye (None, None, 512)    1024        decoder_layer2_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_mha2 (MultiHeadA (None, None, 512)    262144      decoder_layer2_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, None, 512)    0           decoder_layer2_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual2 (Add)  (None, None, 512)    0           decoder_layer2_layernorm1[0][0]  \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm2 (Laye (None, None, 512)    1024        decoder_layer2_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_ffn1 (Dense)     (None, None, 512)    262656      decoder_layer2_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_ffn2 (Dense)     (None, None, 512)    262656      decoder_layer2_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, 512)    0           decoder_layer2_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual3 (Add)  (None, None, 512)    0           decoder_layer2_layernorm2[0][0]  \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm3 (Laye (None, None, 512)    1024        decoder_layer2_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_mha1 (MultiHeadA (None, None, 512)    262144      decoder_layer2_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, None, 512)    0           decoder_layer3_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual1 (Add)  (None, None, 512)    0           decoder_layer2_layernorm3[0][0]  \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm1 (Laye (None, None, 512)    1024        decoder_layer3_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_mha2 (MultiHeadA (None, None, 512)    262144      decoder_layer3_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, None, 512)    0           decoder_layer3_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual2 (Add)  (None, None, 512)    0           decoder_layer3_layernorm1[0][0]  \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm2 (Laye (None, None, 512)    1024        decoder_layer3_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_ffn1 (Dense)     (None, None, 512)    262656      decoder_layer3_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_ffn2 (Dense)     (None, None, 512)    262656      decoder_layer3_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, None, 512)    0           decoder_layer3_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual3 (Add)  (None, None, 512)    0           decoder_layer3_layernorm2[0][0]  \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm3 (Laye (None, None, 512)    1024        decoder_layer3_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_mha1 (MultiHeadA (None, None, 512)    262144      decoder_layer3_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, None, 512)    0           decoder_layer4_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual1 (Add)  (None, None, 512)    0           decoder_layer3_layernorm3[0][0]  \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm1 (Laye (None, None, 512)    1024        decoder_layer4_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_mha2 (MultiHeadA (None, None, 512)    262144      decoder_layer4_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, None, 512)    0           decoder_layer4_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual2 (Add)  (None, None, 512)    0           decoder_layer4_layernorm1[0][0]  \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm2 (Laye (None, None, 512)    1024        decoder_layer4_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_ffn1 (Dense)     (None, None, 512)    262656      decoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_ffn2 (Dense)     (None, None, 512)    262656      decoder_layer4_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, 512)    0           decoder_layer4_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual3 (Add)  (None, None, 512)    0           decoder_layer4_layernorm2[0][0]  \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm3 (Laye (None, None, 512)    1024        decoder_layer4_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_mha1 (MultiHeadA (None, None, 512)    262144      decoder_layer4_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, None, 512)    0           decoder_layer5_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_residual1 (Add)  (None, None, 512)    0           decoder_layer4_layernorm3[0][0]  \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_layernorm1 (Laye (None, None, 512)    1024        decoder_layer5_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_mha2 (MultiHeadA (None, None, 512)    262144      decoder_layer5_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, None, 512)    0           decoder_layer5_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_residual2 (Add)  (None, None, 512)    0           decoder_layer5_layernorm1[0][0]  \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_layernorm2 (Laye (None, None, 512)    1024        decoder_layer5_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_ffn1 (Dense)     (None, None, 512)    262656      decoder_layer5_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_ffn2 (Dense)     (None, None, 512)    262656      decoder_layer5_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, None, 512)    0           decoder_layer5_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_residual3 (Add)  (None, None, 512)    0           decoder_layer5_layernorm2[0][0]  \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_layernorm3 (Laye (None, None, 512)    1024        decoder_layer5_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_mha1 (MultiHeadA (None, None, 512)    262144      decoder_layer5_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, None, 512)    0           decoder_layer6_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_residual1 (Add)  (None, None, 512)    0           decoder_layer5_layernorm3[0][0]  \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_layernorm1 (Laye (None, None, 512)    1024        decoder_layer6_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_mha2 (MultiHeadA (None, None, 512)    262144      decoder_layer6_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, None, 512)    0           decoder_layer6_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_residual2 (Add)  (None, None, 512)    0           decoder_layer6_layernorm1[0][0]  \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_layernorm2 (Laye (None, None, 512)    1024        decoder_layer6_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_ffn1 (Dense)     (None, None, 512)    262656      decoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_ffn2 (Dense)     (None, None, 512)    262656      decoder_layer6_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, None, 512)    0           decoder_layer6_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_residual3 (Add)  (None, None, 512)    0           decoder_layer6_layernorm2[0][0]  \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_layernorm3 (Laye (None, None, 512)    1024        decoder_layer6_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "shared_weights_1 (SharedWeights (None, None, 10001)  0           decoder_layer6_layernorm3[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 16,173,568\n",
      "Trainable params: 16,173,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PLACEHOLDER = tf.placeholder(dtype='int32', shape=(None, SENTENCE_LEN))\n",
    "model.compile(\n",
    "    loss=LOSS,\n",
    "    optimizer=OPTIMIZER,\n",
    "#    metrics=METRICS,\n",
    "    target_tensors=[TARGET_PLACEHOLDER],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity:    10001.00000000001\tentropy:    9.210440366976517\n",
      "perplexity:    8103.083927575384\tentropy:                    9\n",
      "perplexity:   2980.9579870417283\tentropy:                    8\n",
      "perplexity:   1096.6331584284585\tentropy:                    7\n",
      "perplexity:    403.4287934927351\tentropy:                    6\n",
      "perplexity:    148.4131591025766\tentropy:                    5\n",
      "perplexity:   54.598150033144236\tentropy:                    4\n",
      "perplexity:   20.085536923187668\tentropy:                    3\n",
      "perplexity:     7.38905609893065\tentropy:                    2\n",
      "perplexity:    2.718281828459045\tentropy:                    1\n",
      "perplexity:                  1.0\tentropy:                    0\n"
     ]
    }
   ],
   "source": [
    "# print loss values for reference\n",
    "def display_loss_reference():\n",
    "    format_ = 'perplexity: %20s\\tentropy: %20s'\n",
    "    upper_limit = np.log(VOCAB_SIZE)\n",
    "    print(format_ % (np.exp(upper_limit), upper_limit))\n",
    "    for i in reversed(range(int(np.floor(upper_limit))+1)):\n",
    "        print(format_ % (np.exp(i), i))\n",
    "display_loss_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display entropy, perplexity reference\n",
    "max_entropy = np.log(VOCAB_SIZE)\n",
    "entropy = np.array(list(range(np.ceil(max_entropy))) + [max_entropy])\n",
    "pd.DataFrame({'perplexity': np.exp(entropy), 'entropy': entropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 9.2026exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2816s 282ms/step - loss: 9.2026 - val_loss: 9.1749\n",
      "Epoch 2/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 9.1487exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2804s 280ms/step - loss: 9.1487 - val_loss: 9.1109\n",
      "Epoch 3/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 9.0869exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2806s 281ms/step - loss: 9.0869 - val_loss: 9.0453\n",
      "Epoch 4/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 9.0249exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2808s 281ms/step - loss: 9.0249 - val_loss: 8.9807\n",
      "Epoch 5/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.9640exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2806s 281ms/step - loss: 8.9640 - val_loss: 8.9178\n",
      "Epoch 6/30\n",
      " 3513/10000 [=========>....................] - ETA: 30:16 - loss: 8.9227exhausted `items`, repeating\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.9021exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2815s 281ms/step - loss: 8.9021 - val_loss: 8.8528\n",
      "Epoch 7/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.8359exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2812s 281ms/step - loss: 8.8358 - val_loss: 8.7813\n",
      "Epoch 8/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.7607exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2809s 281ms/step - loss: 8.7607 - val_loss: 8.7010\n",
      "Epoch 9/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.6759exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2815s 281ms/step - loss: 8.6759 - val_loss: 8.6099\n",
      "Epoch 10/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.5804exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2796s 280ms/step - loss: 8.5804 - val_loss: 8.5077\n",
      "Epoch 11/30\n",
      " 7036/10000 [====================>.........] - ETA: 13:48 - loss: 8.4899exhausted `items`, repeating\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.4730exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2815s 281ms/step - loss: 8.4730 - val_loss: 8.3940\n",
      "Epoch 12/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.3546exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2795s 279ms/step - loss: 8.3546 - val_loss: 8.2692\n",
      "Epoch 13/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.2250exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2801s 280ms/step - loss: 8.2250 - val_loss: 8.1352\n",
      "Epoch 14/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 8.0886exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2803s 280ms/step - loss: 8.0886 - val_loss: 7.9946\n",
      "Epoch 15/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 7.9458exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2795s 280ms/step - loss: 7.9458 - val_loss: 7.8510\n",
      "Epoch 16/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 7.8036exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2806s 281ms/step - loss: 7.8036 - val_loss: 7.7109\n",
      "Epoch 17/30\n",
      "  559/10000 [>.............................] - ETA: 44:28 - loss: 7.7311exhausted `items`, repeating\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 7.6666exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2799s 280ms/step - loss: 7.6666 - val_loss: 7.5824\n",
      "Epoch 18/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 7.5466exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2800s 280ms/step - loss: 7.5466 - val_loss: 7.4776\n",
      "Epoch 19/30\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 7.4543exhausted `items`, repeating\n",
      "10000/10000 [==============================] - 2803s 280ms/step - loss: 7.4542 - val_loss: 7.4068\n",
      "Epoch 20/30\n",
      " 3640/10000 [=========>....................] - ETA: 29:32 - loss: 7.4086"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    TRAIN_GEN,\n",
    "    steps_per_epoch=N_TRAIN_STEPS,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_data=TEST_GEN,\n",
    "    validation_steps=N_VALIDATION_STEPS,\n",
    "    callbacks=CALLBACKS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
