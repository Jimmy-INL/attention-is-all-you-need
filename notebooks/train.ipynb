{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- label smoothing\n",
    "- calculate average number of pad/unkown tokens used\n",
    "- generate forever from list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more configs for training are defined later\n",
    "TRAINING_DIRECTORY = '../data/preprocessed_stories'\n",
    "EXTENSION = '.clean'\n",
    "N_TRAIN_FILES = 100000\n",
    "N_TEST_FILES = 500\n",
    "TOKENS_PER_BATCH = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # show tensor2tensor hparams for summarization for reference\n",
    "# import tensor2tensor.models.transformer\n",
    "# from tensor2tensor.utils.registry import hparams\n",
    "# params = hparams('transformer_prepend')()\n",
    "# for k, v in sorted(vars(params).items(), key=lambda tup: tup[0]):\n",
    "#     if not k.startswith('_') and not callable(v):\n",
    "#         print(f'{k}={v!r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/preprocessed_stories/8bea156c50b9bb04ef1804a13971c381e63b790f.clean',\n",
       " '../data/preprocessed_stories/96f71e32fad9bfef59c4a67b021609cf86b126de.clean',\n",
       " '../data/preprocessed_stories/50a945a090973a747082435b6f4bfd1da7922ad6.clean',\n",
       " '../data/preprocessed_stories/0e2569c383c66c3491f16029af147019d79a2480.clean',\n",
       " '../data/preprocessed_stories/17c1d1ff679615f250f545750a3fa7feddc9a9ca.clean',\n",
       " '../data/preprocessed_stories/7471e1359d1b9e0440d948ee116089b109d005c3.clean',\n",
       " '../data/preprocessed_stories/b7470294d56d294e4fd9801f190ae92352e1216a.clean',\n",
       " '../data/preprocessed_stories/021d78038eef6d680537762a51963f514059ea97.clean',\n",
       " '../data/preprocessed_stories/debcabe9677c446e3fbb8851f225cb30d38beea6.clean',\n",
       " '../data/preprocessed_stories/b2fcb5fce5937b69c882a09151ba83c084fa4ad4.clean']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = glob.glob('%s/*%s' % (TRAINING_DIRECTORY, EXTENSION))\n",
    "print(len(FILES))\n",
    "FILES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = FILES[:N_TRAIN_FILES]\n",
    "TEST_FILES = FILES[N_TRAIN_FILES:N_TRAIN_FILES+N_TEST_FILES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define batch generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "\n",
    "class BytePairEncoder:\n",
    "    def __init__(self, vocab_size, model_name, *, model_file=None, vocab_file=None,\n",
    "                 training_file=None, processor=None, **kwargs):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model_name = model_name\n",
    "        self.training_file = training_file\n",
    "        self.model_file = f'{self.model_name}.model' if model_file is None else model_file\n",
    "        self.vocab_file = f'{self.model_name}.vocab' if vocab_file is None else vocab_file\n",
    "        if processor is None:\n",
    "            if training_file is None:\n",
    "                raise ValueError('training_file cannot be None when processor is also None.')\n",
    "            processor = self._fit(input=training_file, vocab_size=vocab_size,\n",
    "                                  model_prefix=model_name, model_type='bpe',\n",
    "                                  **kwargs)\n",
    "        self.processor = processor\n",
    "        \n",
    "    def encode(self, text):\n",
    "        return np.array(self.processor.EncodeAsIds(text))\n",
    "    \n",
    "    def encode_as_pieces(self, text):\n",
    "        return self.processor.EncodeAsPieces(text)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.processor.DecodeIds(ids.tolist())\n",
    "    \n",
    "    def decode_pieces(self, pieces):\n",
    "        return self.processor.DecodePieces(pieces)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, model_file, vocab_file):\n",
    "        model_name = model_file.partition('.')[0]\n",
    "        processor = cls._load_model(model_file)\n",
    "        for vocab_size, _ in enumerate(open(vocab_file), start=1): pass\n",
    "        return cls(vocab_size=vocab_size, model_name=model_name, processor=processor,\n",
    "                   model_file=model_file, vocab_file=vocab_file)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_model(filename):\n",
    "        processor = spm.SentencePieceProcessor()\n",
    "        processor.Load(filename)\n",
    "        return processor\n",
    "        \n",
    "    def _fit(self, **kwargs):\n",
    "        params = ' '.join([f'--{k}={v}' for k, v in kwargs.items()])\n",
    "        spm.SentencePieceTrainer.Train(params)\n",
    "        processor = self._load_model(self.model_file)\n",
    "        return processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained in byte-pair-encoding\n",
    "TOKENIZER = BytePairEncoder.from_files('summarizer.model', 'summarizer.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENIZER.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingExample:\n",
    "    \"\"\"Simple container to keep track of training data. Useful for debugging.\"\"\"\n",
    "    def __init__(self, item, context_text, target_text, context_tokens,\n",
    "                 target_tokens, filename):\n",
    "        self.item = item\n",
    "        self.context_text = context_text\n",
    "        self.target_text = target_text\n",
    "        self.context_tokens = context_tokens\n",
    "        self.target_tokens = target_tokens\n",
    "        self.filename = filename\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.context_tokens) + len(self.target_tokens)\n",
    "\n",
    "def load_files(files, tokenizer):\n",
    "    \"\"\"Load and tokenize files.\"\"\"\n",
    "    training_examples = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            context_text, target_text = f.read().split('\\t')\n",
    "        context_tokens = tokenizer(context_text)\n",
    "        target_tokens = tokenizer(target_text)\n",
    "        example = TrainingExample(file, context_text, target_text,\n",
    "                                  context_tokens, target_tokens,\n",
    "                                  file)\n",
    "        training_examples.append(example)\n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336a3d0b466949a4a3230dc8346e540b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2.16 s, sys: 18.9 ms, total: 2.18 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "TRAINING_EXAMPLES = load_files(tqdm(TRAIN_FILES[:1000]), TOKENIZER.encode)\n",
    "# sort files by number of tokens to reduce padding\n",
    "TRAINING_EXAMPLES = sorted(TRAINING_EXAMPLES, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[133,\n",
       " 159,\n",
       " 159,\n",
       " 179,\n",
       " 196,\n",
       " 208,\n",
       " 219,\n",
       " 227,\n",
       " 232,\n",
       " 234,\n",
       " 237,\n",
       " 241,\n",
       " 242,\n",
       " 244,\n",
       " 273,\n",
       " 275,\n",
       " 288,\n",
       " 292,\n",
       " 293,\n",
       " 298,\n",
       " 301,\n",
       " 302,\n",
       " 302,\n",
       " 305,\n",
       " 318,\n",
       " 319,\n",
       " 323,\n",
       " 323,\n",
       " 325,\n",
       " 332,\n",
       " 345,\n",
       " 345,\n",
       " 345,\n",
       " 346,\n",
       " 346,\n",
       " 351,\n",
       " 359,\n",
       " 361,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 370,\n",
       " 378,\n",
       " 380,\n",
       " 381,\n",
       " 383,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 393,\n",
       " 395,\n",
       " 396,\n",
       " 396,\n",
       " 397,\n",
       " 399,\n",
       " 404,\n",
       " 411,\n",
       " 414,\n",
       " 417,\n",
       " 423,\n",
       " 423,\n",
       " 424,\n",
       " 427,\n",
       " 429,\n",
       " 429,\n",
       " 431,\n",
       " 433,\n",
       " 434,\n",
       " 437,\n",
       " 437,\n",
       " 441,\n",
       " 445,\n",
       " 445,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 451,\n",
       " 451,\n",
       " 455,\n",
       " 456,\n",
       " 456,\n",
       " 456,\n",
       " 457,\n",
       " 461,\n",
       " 462,\n",
       " 464,\n",
       " 467,\n",
       " 468,\n",
       " 468,\n",
       " 468,\n",
       " 469,\n",
       " 469,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 476,\n",
       " 477,\n",
       " 477,\n",
       " 478,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 483,\n",
       " 483,\n",
       " 485,\n",
       " 485,\n",
       " 490,\n",
       " 493,\n",
       " 495,\n",
       " 498,\n",
       " 502,\n",
       " 502,\n",
       " 502,\n",
       " 508,\n",
       " 509,\n",
       " 513,\n",
       " 515,\n",
       " 516,\n",
       " 519,\n",
       " 526,\n",
       " 526,\n",
       " 527,\n",
       " 530,\n",
       " 533,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 537,\n",
       " 538,\n",
       " 540,\n",
       " 541,\n",
       " 543,\n",
       " 543,\n",
       " 543,\n",
       " 543,\n",
       " 543,\n",
       " 544,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 547,\n",
       " 549,\n",
       " 549,\n",
       " 552,\n",
       " 555,\n",
       " 559,\n",
       " 559,\n",
       " 560,\n",
       " 560,\n",
       " 561,\n",
       " 561,\n",
       " 563,\n",
       " 564,\n",
       " 564,\n",
       " 567,\n",
       " 567,\n",
       " 568,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 574,\n",
       " 574,\n",
       " 582,\n",
       " 584,\n",
       " 584,\n",
       " 584,\n",
       " 586,\n",
       " 586,\n",
       " 586,\n",
       " 586,\n",
       " 587,\n",
       " 587,\n",
       " 588,\n",
       " 591,\n",
       " 591,\n",
       " 591,\n",
       " 592,\n",
       " 594,\n",
       " 596,\n",
       " 596,\n",
       " 598,\n",
       " 599,\n",
       " 601,\n",
       " 603,\n",
       " 606,\n",
       " 609,\n",
       " 609,\n",
       " 609,\n",
       " 611,\n",
       " 613,\n",
       " 613,\n",
       " 613,\n",
       " 613,\n",
       " 615,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 617,\n",
       " 618,\n",
       " 618,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 622,\n",
       " 623,\n",
       " 623,\n",
       " 624,\n",
       " 624,\n",
       " 626,\n",
       " 626,\n",
       " 631,\n",
       " 631,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 639,\n",
       " 640,\n",
       " 643,\n",
       " 643,\n",
       " 644,\n",
       " 646,\n",
       " 647,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 655,\n",
       " 655,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 660,\n",
       " 662,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 666,\n",
       " 666,\n",
       " 669,\n",
       " 672,\n",
       " 674,\n",
       " 674,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 679,\n",
       " 679,\n",
       " 679,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 684,\n",
       " 684,\n",
       " 685,\n",
       " 688,\n",
       " 690,\n",
       " 690,\n",
       " 690,\n",
       " 691,\n",
       " 691,\n",
       " 693,\n",
       " 693,\n",
       " 694,\n",
       " 694,\n",
       " 694,\n",
       " 695,\n",
       " 697,\n",
       " 702,\n",
       " 702,\n",
       " 703,\n",
       " 705,\n",
       " 706,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 716,\n",
       " 718,\n",
       " 718,\n",
       " 718,\n",
       " 719,\n",
       " 719,\n",
       " 722,\n",
       " 723,\n",
       " 723,\n",
       " 725,\n",
       " 726,\n",
       " 726,\n",
       " 728,\n",
       " 728,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 741,\n",
       " 744,\n",
       " 744,\n",
       " 744,\n",
       " 745,\n",
       " 747,\n",
       " 748,\n",
       " 751,\n",
       " 753,\n",
       " 753,\n",
       " 753,\n",
       " 753,\n",
       " 753,\n",
       " 754,\n",
       " 756,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 760,\n",
       " 760,\n",
       " 762,\n",
       " 764,\n",
       " 766,\n",
       " 767,\n",
       " 767,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 771,\n",
       " 771,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 783,\n",
       " 785,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 789,\n",
       " 792,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 800,\n",
       " 800,\n",
       " 801,\n",
       " 804,\n",
       " 804,\n",
       " 805,\n",
       " 805,\n",
       " 806,\n",
       " 806,\n",
       " 807,\n",
       " 809,\n",
       " 809,\n",
       " 811,\n",
       " 811,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 818,\n",
       " 820,\n",
       " 821,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 829,\n",
       " 831,\n",
       " 831,\n",
       " 833,\n",
       " 833,\n",
       " 835,\n",
       " 837,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 839,\n",
       " 840,\n",
       " 840,\n",
       " 842,\n",
       " 844,\n",
       " 844,\n",
       " 844,\n",
       " 845,\n",
       " 845,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 858,\n",
       " 859,\n",
       " 861,\n",
       " 862,\n",
       " 865,\n",
       " 867,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 872,\n",
       " 874,\n",
       " 874,\n",
       " 876,\n",
       " 877,\n",
       " 877,\n",
       " 880,\n",
       " 882,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 884,\n",
       " 887,\n",
       " 887,\n",
       " 887,\n",
       " 889,\n",
       " 890,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 899,\n",
       " 899,\n",
       " 899,\n",
       " 900,\n",
       " 900,\n",
       " 903,\n",
       " 904,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 907,\n",
       " 907,\n",
       " 908,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 916,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 924,\n",
       " 924,\n",
       " 925,\n",
       " 928,\n",
       " 929,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 936,\n",
       " 937,\n",
       " 937,\n",
       " 937,\n",
       " 938,\n",
       " 940,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 945,\n",
       " 945,\n",
       " 945,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 951,\n",
       " 952,\n",
       " 952,\n",
       " 954,\n",
       " 957,\n",
       " 960,\n",
       " 962,\n",
       " 962,\n",
       " 964,\n",
       " 964,\n",
       " 964,\n",
       " 964,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 974,\n",
       " 974,\n",
       " 976,\n",
       " 978,\n",
       " 979,\n",
       " 979,\n",
       " 979,\n",
       " 979,\n",
       " 981,\n",
       " 981,\n",
       " 984,\n",
       " 985,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 989,\n",
       " 991,\n",
       " 991,\n",
       " 992,\n",
       " 992,\n",
       " 994,\n",
       " 995,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 999,\n",
       " 999,\n",
       " 999,\n",
       " 1002,\n",
       " 1003,\n",
       " 1004,\n",
       " 1004,\n",
       " 1005,\n",
       " 1005,\n",
       " 1006,\n",
       " 1006,\n",
       " 1007,\n",
       " 1012,\n",
       " 1012,\n",
       " 1013,\n",
       " 1016,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1027,\n",
       " 1028,\n",
       " 1029,\n",
       " 1030,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1035,\n",
       " 1035,\n",
       " 1035,\n",
       " 1040,\n",
       " 1040,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1052,\n",
       " 1052,\n",
       " 1054,\n",
       " 1056,\n",
       " 1056,\n",
       " 1057,\n",
       " 1059,\n",
       " 1061,\n",
       " 1064,\n",
       " 1065,\n",
       " 1065,\n",
       " 1065,\n",
       " 1065,\n",
       " 1066,\n",
       " 1069,\n",
       " 1069,\n",
       " 1069,\n",
       " 1070,\n",
       " 1070,\n",
       " 1072,\n",
       " 1072,\n",
       " 1073,\n",
       " 1076,\n",
       " 1076,\n",
       " 1078,\n",
       " 1081,\n",
       " 1081,\n",
       " 1081,\n",
       " 1082,\n",
       " 1082,\n",
       " 1085,\n",
       " 1087,\n",
       " 1088,\n",
       " 1088,\n",
       " 1089,\n",
       " 1090,\n",
       " 1091,\n",
       " 1092,\n",
       " 1093,\n",
       " 1095,\n",
       " 1096,\n",
       " 1097,\n",
       " 1098,\n",
       " 1099,\n",
       " 1103,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1107,\n",
       " 1116,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1123,\n",
       " 1125,\n",
       " 1126,\n",
       " 1128,\n",
       " 1128,\n",
       " 1128,\n",
       " 1132,\n",
       " 1132,\n",
       " 1134,\n",
       " 1135,\n",
       " 1138,\n",
       " 1139,\n",
       " 1142,\n",
       " 1143,\n",
       " 1145,\n",
       " 1145,\n",
       " 1148,\n",
       " 1149,\n",
       " 1150,\n",
       " 1153,\n",
       " 1155,\n",
       " 1156,\n",
       " 1157,\n",
       " 1158,\n",
       " 1159,\n",
       " 1165,\n",
       " 1165,\n",
       " 1166,\n",
       " 1166,\n",
       " 1167,\n",
       " 1168,\n",
       " 1168,\n",
       " 1170,\n",
       " 1170,\n",
       " 1175,\n",
       " 1175,\n",
       " 1177,\n",
       " 1180,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1184,\n",
       " 1187,\n",
       " 1188,\n",
       " 1188,\n",
       " 1193,\n",
       " 1194,\n",
       " 1199,\n",
       " 1199,\n",
       " 1201,\n",
       " 1204,\n",
       " 1205,\n",
       " 1206,\n",
       " 1211,\n",
       " 1212,\n",
       " 1212,\n",
       " 1215,\n",
       " 1222,\n",
       " 1224,\n",
       " 1227,\n",
       " 1228,\n",
       " 1228,\n",
       " 1228,\n",
       " 1231,\n",
       " 1234,\n",
       " 1234,\n",
       " 1240,\n",
       " 1240,\n",
       " 1244,\n",
       " 1245,\n",
       " 1246,\n",
       " 1246,\n",
       " 1246,\n",
       " 1247,\n",
       " 1248,\n",
       " 1252,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1258,\n",
       " 1261,\n",
       " 1261,\n",
       " 1263,\n",
       " 1270,\n",
       " 1278,\n",
       " 1281,\n",
       " 1284,\n",
       " 1286,\n",
       " 1287,\n",
       " 1288,\n",
       " 1289,\n",
       " 1293,\n",
       " 1293,\n",
       " 1295,\n",
       " 1295,\n",
       " 1296,\n",
       " 1299,\n",
       " 1300,\n",
       " 1301,\n",
       " 1302,\n",
       " 1303,\n",
       " 1305,\n",
       " 1306,\n",
       " 1307,\n",
       " 1308,\n",
       " 1308,\n",
       " 1315,\n",
       " 1315,\n",
       " 1317,\n",
       " 1318,\n",
       " 1326,\n",
       " 1327,\n",
       " 1327,\n",
       " 1328,\n",
       " 1329,\n",
       " 1331,\n",
       " 1332,\n",
       " 1333,\n",
       " 1335,\n",
       " 1337,\n",
       " 1338,\n",
       " 1338,\n",
       " 1340,\n",
       " 1340,\n",
       " 1342,\n",
       " 1342,\n",
       " 1344,\n",
       " 1344,\n",
       " 1345,\n",
       " 1347,\n",
       " 1348,\n",
       " 1350,\n",
       " 1351,\n",
       " 1351,\n",
       " 1352,\n",
       " 1353,\n",
       " 1354,\n",
       " 1358,\n",
       " 1362,\n",
       " 1367,\n",
       " 1368,\n",
       " 1368,\n",
       " 1371,\n",
       " 1374,\n",
       " 1379,\n",
       " 1380,\n",
       " 1381,\n",
       " 1382,\n",
       " 1387,\n",
       " 1390,\n",
       " 1393,\n",
       " 1393,\n",
       " 1394,\n",
       " 1395,\n",
       " 1397,\n",
       " 1399,\n",
       " 1402,\n",
       " 1403,\n",
       " 1408,\n",
       " 1410,\n",
       " 1410,\n",
       " 1418,\n",
       " 1419,\n",
       " 1421,\n",
       " 1423,\n",
       " 1424,\n",
       " 1426,\n",
       " 1435,\n",
       " 1435,\n",
       " 1436,\n",
       " 1436,\n",
       " 1437,\n",
       " 1438,\n",
       " 1439,\n",
       " 1440,\n",
       " 1447,\n",
       " 1448,\n",
       " 1453,\n",
       " 1454,\n",
       " 1457,\n",
       " 1458,\n",
       " 1458,\n",
       " 1460,\n",
       " 1460,\n",
       " 1460,\n",
       " 1469,\n",
       " 1472,\n",
       " 1478,\n",
       " 1480,\n",
       " 1486,\n",
       " 1490,\n",
       " 1493,\n",
       " 1496,\n",
       " 1498,\n",
       " 1504,\n",
       " 1507,\n",
       " 1508,\n",
       " 1511,\n",
       " 1511,\n",
       " 1520,\n",
       " 1523,\n",
       " 1525,\n",
       " 1527,\n",
       " 1534,\n",
       " 1535,\n",
       " 1536,\n",
       " 1536,\n",
       " 1538,\n",
       " 1538,\n",
       " 1539,\n",
       " 1540,\n",
       " 1542,\n",
       " 1542,\n",
       " 1550,\n",
       " 1550,\n",
       " 1556,\n",
       " 1557,\n",
       " 1563,\n",
       " 1570,\n",
       " 1572,\n",
       " 1576,\n",
       " 1576,\n",
       " 1577,\n",
       " 1580,\n",
       " 1580,\n",
       " 1583,\n",
       " 1588,\n",
       " 1588,\n",
       " 1590,\n",
       " 1593,\n",
       " 1594,\n",
       " 1597,\n",
       " 1617,\n",
       " 1631,\n",
       " 1633,\n",
       " 1634,\n",
       " 1636,\n",
       " 1637,\n",
       " 1648,\n",
       " 1650,\n",
       " 1651,\n",
       " 1651,\n",
       " 1666,\n",
       " 1668,\n",
       " 1670,\n",
       " 1671,\n",
       " 1675,\n",
       " 1677,\n",
       " 1678,\n",
       " 1679,\n",
       " 1679,\n",
       " 1681,\n",
       " 1690,\n",
       " 1691,\n",
       " 1692,\n",
       " 1700,\n",
       " 1705,\n",
       " 1712,\n",
       " 1713,\n",
       " 1718,\n",
       " 1720,\n",
       " 1720,\n",
       " 1725,\n",
       " 1725,\n",
       " 1734,\n",
       " 1735,\n",
       " 1740,\n",
       " 1744,\n",
       " 1748,\n",
       " 1750,\n",
       " 1752,\n",
       " 1761,\n",
       " 1764,\n",
       " 1772,\n",
       " 1778,\n",
       " 1786,\n",
       " 1790,\n",
       " 1795,\n",
       " 1806,\n",
       " 1813,\n",
       " 1828,\n",
       " 1837,\n",
       " 1858,\n",
       " 1861,\n",
       " 1866,\n",
       " 1868,\n",
       " 1873,\n",
       " 1875,\n",
       " 1884,\n",
       " 1889,\n",
       " 1894,\n",
       " 1909,\n",
       " 1916,\n",
       " 1938,\n",
       " 1939,\n",
       " 1947,\n",
       " 1947,\n",
       " 1947,\n",
       " 1968,\n",
       " 1976,\n",
       " 1980,\n",
       " 1982,\n",
       " 1992,\n",
       " 1993,\n",
       " 1994,\n",
       " 1997,\n",
       " 2004,\n",
       " 2004,\n",
       " 2009,\n",
       " 2016,\n",
       " 2017,\n",
       " 2033,\n",
       " 2068,\n",
       " 2071,\n",
       " 2080,\n",
       " 2101,\n",
       " 2105,\n",
       " 2107,\n",
       " 2110,\n",
       " 2124,\n",
       " 2130,\n",
       " 2136,\n",
       " 2151,\n",
       " 2186,\n",
       " 2190,\n",
       " 2206,\n",
       " 2219,\n",
       " 2221,\n",
       " 2240,\n",
       " 2243,\n",
       " 2248,\n",
       " 2253,\n",
       " 2260,\n",
       " 2271,\n",
       " 2282,\n",
       " 2287,\n",
       " 2289,\n",
       " 2289,\n",
       " 2309,\n",
       " 2309,\n",
       " 2330,\n",
       " 2346,\n",
       " 2376,\n",
       " 2382,\n",
       " 2391,\n",
       " 2440,\n",
       " 2450,\n",
       " 2567,\n",
       " 2609]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in TRAINING_EXAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data import BaseBatchGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class SummaryBatchGenerator(BaseBatchGenerator):\n",
    "    def __init__(self, max_context_len=None, max_target_len=None, pad_token=0,\n",
    "                 bos_token=1, eos_token=2, prepend=False):\n",
    "        self.max_context_len = max_context_len\n",
    "        self.max_target_len = max_target_len\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.pad_token = pad_token\n",
    "        self.prepend = prepend\n",
    "\n",
    "    def generate_steps(self, item):\n",
    "        example = item  # alias\n",
    "        if self.max_target_len is not None \\\n",
    "                and len(example.target_tokens) > self.max_target_len:\n",
    "            return []\n",
    "        if self.max_context_len is not None:\n",
    "            encoder_tokens = example.context_tokens[:self.max_context_len]\n",
    "        else:\n",
    "            encoder_tokens = example.context_tokens\n",
    "        if self.prepend:\n",
    "            decoder_tokens = np.append(example.context_tokens, self.eos_token)\n",
    "        else:\n",
    "            decoder_tokens = np.array([])\n",
    "        decoder_tokens = np.append(decoder_tokens, example.target_tokens)\n",
    "        decoder_tokens = np.append(decoder_tokens, self.eos_token)\n",
    "        training_step = encoder_tokens, decoder_tokens, len(example)\n",
    "        return [training_step]\n",
    "\n",
    "    def generate_batches(self, steps, batch_size):\n",
    "        batches = []\n",
    "        min_batch_size = 0.95 * batch_size\n",
    "        max_batch_size = 1.05 * batch_size\n",
    "        step_sizes = [size for _, _, size in steps]\n",
    "        current_batch_x1s = []\n",
    "        current_batch_x2s = []\n",
    "        items = enumerate(zip(steps, step_sizes, step_sizes[1:]))\n",
    "        max_used_i = 0\n",
    "        for i, (step, step_size, next_step_size) in items:\n",
    "            if step_size > max_batch_size:\n",
    "                print(f'skipping step with size {step_size}')\n",
    "                continue\n",
    "            encoder_tokens, decoder_tokens, _ = step\n",
    "            current_batch_x1s.append(encoder_tokens)\n",
    "            current_batch_x2s.append(decoder_tokens)\n",
    "            next_batch_size = (len(current_batch_x1s) + 1) * next_step_size  # account for padding\n",
    "            if next_batch_size > max_batch_size:\n",
    "                max_used_i = i\n",
    "                x1 = pad_sequences(current_batch_x1s, value=self.pad_token, padding='post')\n",
    "                x2 = pad_sequences(current_batch_x2s, value=self.pad_token, padding='post')\n",
    "                X = [x1, x2[:,:-1]]\n",
    "                y = x2[:,1:]\n",
    "                batches.append((X, y))\n",
    "                current_batch_x1s, current_batch_x2s = [], []\n",
    "            # if there aren't enough steps left to create a full sized batch\n",
    "            # then break, the leftover steps will be added to the next call\n",
    "            # to generate_batches()\n",
    "            if sum(step_sizes[i+1:]) < batch_size:\n",
    "                break\n",
    "        return (batches, steps[max_used_i+1:]) if max_used_i > 0 else (batches, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_GENERATOR = SummaryBatchGenerator(pad_token=TOKENIZER.vocab_size, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epoch_generator = BATCH_GENERATOR.generate_epoch(TRAINING_EXAMPLES, batch_size=TOKENS_PER_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = list(epoch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x1.shape[0] for (x1, _), _ in epoch), len(TRAINING_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOD: if we skip a training example because it is too large this will fail eroneously\n",
    "# assert sum(x1.shape[0] for (x1, _), _ in epoch) == len(TRAINING_EXAMPLES), \\\n",
    "#    'number of steps in batch does not equal number of examples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_training_steps(x1, x2, y):\n",
    "    print(TOKENIZER.decode(x1))\n",
    "    print('\\n')\n",
    "    print(TOKENIZER.decode(x2))\n",
    "    print('\\n')\n",
    "    print(TOKENIZER.decode(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1, x2), y = epoch[0]\n",
    "# view_training_steps(x1[0], x2[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 244) (15, 274)\n",
      "(1, 2518) (1, 2568)\n"
     ]
    }
   ],
   "source": [
    "(x1, x2), y = epoch[0]\n",
    "print(x1.shape, x2.shape)\n",
    "(x1, x2), y = epoch[-1]\n",
    "print(x1.shape, x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2518), (1, 2568))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'x1_tok': 1004188,\n",
       "             'x1_pad': 10001,\n",
       "             'x1_unk': 1691,\n",
       "             'x1_avg_seq_len': 1293.2727272727273,\n",
       "             'x2_tok': 1044180,\n",
       "             'x2_pad': 3249,\n",
       "             'x2_unk': 1727,\n",
       "             'x2_avg_seq_len': 1327.949494949495})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "def calc_stats(epoch, pad_token, unkown_token):\n",
    "    stats = collections.defaultdict(int)\n",
    "    for (x1, x2), y in epoch:\n",
    "        stats['x1_tok'] += ((x1 != pad_token) & (x1 != unkown_token)).sum()\n",
    "        stats['x1_pad'] += (x1 == pad_token).sum()\n",
    "        stats['x1_unk'] += (x1 == unkown_token).sum()\n",
    "        stats['x1_avg_seq_len'] += x1.shape[-1]\n",
    "        stats['x2_tok'] += ((x2 != pad_token) & (x2 != unkown_token)).sum()\n",
    "        stats['x2_pad'] += (x2 == pad_token).sum()\n",
    "        stats['x2_unk'] += (x2 == unkown_token).sum()\n",
    "        stats['x2_avg_seq_len'] += x2.shape[-1]\n",
    "    stats['x1_avg_seq_len'] /= len(epoch)\n",
    "    stats['x2_avg_seq_len'] /= len(epoch)\n",
    "    return stats\n",
    "calc_stats(epoch, BATCH_GENERATOR.pad_token, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build final training generator\n",
    "now that we're happy with the batch generator create one that goes forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forever(items):\n",
    "    while True:\n",
    "        yield from items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_GEN = generate_forever(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for loss/metrics/callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "# on custom implementation rather than keras see\n",
    "# https://github.com/tensorflow/tensorflow/issues/17150\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                          logits=y_pred)\n",
    "\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    return K.exp(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# see\n",
    "# https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/learning_rate.py\n",
    "class LRScheduler:\n",
    "    \"\"\"Stateful learning rate scheduler.\n",
    "    \n",
    "    Useful if training is stopped and then resumed so that scheduling\n",
    "    resumes considering the epoch during which training was interrupted.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, warmup_steps, learning_rate):\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = 1\n",
    "        self.initial_lr = self.lr()\n",
    "\n",
    "    def lr(self, *args):\n",
    "        scalar = 5000 \\\n",
    "               * self.d_model**-0.5 \\\n",
    "               * min(self.epoch * self.warmup_steps**-1.5, self.epoch**-0.5)\n",
    "        self.epoch += 1\n",
    "        return 0.002 * scalar * self.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f199e56037bb483f912217834fe05b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1.13 s, sys: 8.33 ms, total: 1.14 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_EXAMPLES = load_files(tqdm(TEST_FILES[:1000]), TOKENIZER.encode)\n",
    "# sort files by number of tokens to reduce padding\n",
    "VALIDATION_EXAMPLES = sorted(VALIDATION_EXAMPLES, key=lambda x: len(x))\n",
    "TEST_EPOCH = list(BATCH_GENERATOR.generate_epoch(VALIDATION_EXAMPLES, batch_size=TOKENS_PER_BATCH))\n",
    "TEST_GEN = generate_forever(TEST_EPOCH)\n",
    "N_VALIDATION_STEPS = BATCH_GENERATOR.batches_per_epoch(VALIDATION_EXAMPLES, batch_size=TOKENS_PER_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model architecture\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 4\n",
    "D_MODEL = 64*N_HEADS\n",
    "SENTENCE_LEN = None\n",
    "VOCAB_SIZE = TOKENIZER.vocab_size + 1  # +1 accounts for pad token\n",
    "DROPOUT = 0.1\n",
    "OUTPUT_ACTIVATION = 'linear'  # temporary workaround for keras bug - see above\n",
    "\n",
    "# learning rate\n",
    "WARMUP_STEPS = 8_000\n",
    "LEARNING_RATE = 0.2\n",
    "LEARNING_RATE_SCHEDULER = LRScheduler(D_MODEL, WARMUP_STEPS, LEARNING_RATE)\n",
    "\n",
    "# # optimization\n",
    "# # https://arxiv.org/pdf/1804.00247.pdf\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.98\n",
    "EPSILON = 1e-9\n",
    "OPTIMIZER = adam(lr=LEARNING_RATE_SCHEDULER.initial_lr, beta_1=BETA_1, beta_2=BETA_2, epsilon=EPSILON)\n",
    "METRICS = [sparse_categorical_crossentropy]\n",
    "LOSS = perplexity\n",
    "\n",
    "# # batch training\n",
    "N_TRAIN_STEPS = 1_000\n",
    "CALLBACKS = [LearningRateScheduler(LEARNING_RATE_SCHEDULER.lr),\n",
    "             TensorBoard(log_dir='./logs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe32ec5ac18>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "scheduler = LRScheduler(D_MODEL, WARMUP_STEPS, LEARNING_RATE)\n",
    "learning_rates = [scheduler.lr()\n",
    "                  for _ in range(WARMUP_STEPS+20_000)]\n",
    "plt.plot(learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "model = Transformer(\n",
    "    n_heads=N_HEADS,\n",
    "    encoder_layers=N_LAYERS,\n",
    "    decoder_layers=N_LAYERS,\n",
    "    d_model=D_MODEL,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    sequence_len=SENTENCE_LEN,\n",
    "    dropout=DROPOUT,\n",
    "    output_activation=OUTPUT_ACTIVATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_spec (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_spec (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    2560256     encoder_input_spec[0][0]         \n",
      "                                                                 decoder_input_spec[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_1 (Position (None, None, 256)    0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_scalar (Scalar)       (None, None, 256)    0           positional_encoding_1[0][0]      \n",
      "                                                                 positional_encoding_1[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 256)    0           embedding_scalar[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_mha (MultiHeadAt (None, None, 256)    65536       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 256)    0           encoder_layer1_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_residual1 (Add)  (None, None, 256)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_layernorm1 (Laye (None, None, 256)    512         encoder_layer1_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_ffn1 (Dense)     (None, None, 256)    65792       encoder_layer1_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_ffn2 (Dense)     (None, None, 256)    65792       encoder_layer1_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 256)    0           encoder_layer1_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_residual2 (Add)  (None, None, 256)    0           encoder_layer1_layernorm1[0][0]  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_layernorm2 (Laye (None, None, 256)    512         encoder_layer1_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_mha (MultiHeadAt (None, None, 256)    65536       encoder_layer1_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 256)    0           encoder_layer2_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_residual1 (Add)  (None, None, 256)    0           encoder_layer1_layernorm2[0][0]  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_layernorm1 (Laye (None, None, 256)    512         encoder_layer2_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_ffn1 (Dense)     (None, None, 256)    65792       encoder_layer2_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_ffn2 (Dense)     (None, None, 256)    65792       encoder_layer2_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 256)    0           encoder_layer2_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_residual2 (Add)  (None, None, 256)    0           encoder_layer2_layernorm1[0][0]  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_layernorm2 (Laye (None, None, 256)    512         encoder_layer2_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_mha (MultiHeadAt (None, None, 256)    65536       encoder_layer2_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 256)    0           encoder_layer3_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_residual1 (Add)  (None, None, 256)    0           encoder_layer2_layernorm2[0][0]  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_layernorm1 (Laye (None, None, 256)    512         encoder_layer3_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_ffn1 (Dense)     (None, None, 256)    65792       encoder_layer3_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_ffn2 (Dense)     (None, None, 256)    65792       encoder_layer3_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 256)    0           encoder_layer3_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_residual2 (Add)  (None, None, 256)    0           encoder_layer3_layernorm1[0][0]  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_layernorm2 (Laye (None, None, 256)    512         encoder_layer3_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_mha (MultiHeadAt (None, None, 256)    65536       encoder_layer3_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 256)    0           encoder_layer4_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_residual1 (Add)  (None, None, 256)    0           encoder_layer3_layernorm2[0][0]  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_layernorm1 (Laye (None, None, 256)    512         encoder_layer4_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 256)    0           embedding_scalar[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_ffn1 (Dense)     (None, None, 256)    65792       encoder_layer4_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_mha1 (MultiHeadA (None, None, 256)    65536       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_ffn2 (Dense)     (None, None, 256)    65792       encoder_layer4_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 256)    0           decoder_layer1_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 256)    0           encoder_layer4_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual1 (Add)  (None, None, 256)    0           dropout_2[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_residual2 (Add)  (None, None, 256)    0           encoder_layer4_layernorm1[0][0]  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm1 (Laye (None, None, 256)    512         decoder_layer1_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_layernorm2 (Laye (None, None, 256)    512         encoder_layer4_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_mha2 (MultiHeadA (None, None, 256)    65536       decoder_layer1_layernorm1[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 256)    0           decoder_layer1_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual2 (Add)  (None, None, 256)    0           decoder_layer1_layernorm1[0][0]  \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm2 (Laye (None, None, 256)    512         decoder_layer1_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_ffn1 (Dense)     (None, None, 256)    65792       decoder_layer1_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_ffn2 (Dense)     (None, None, 256)    65792       decoder_layer1_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 256)    0           decoder_layer1_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual3 (Add)  (None, None, 256)    0           decoder_layer1_layernorm2[0][0]  \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm3 (Laye (None, None, 256)    512         decoder_layer1_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_mha1 (MultiHeadA (None, None, 256)    65536       decoder_layer1_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 256)    0           decoder_layer2_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual1 (Add)  (None, None, 256)    0           decoder_layer1_layernorm3[0][0]  \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm1 (Laye (None, None, 256)    512         decoder_layer2_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_mha2 (MultiHeadA (None, None, 256)    65536       decoder_layer2_layernorm1[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 256)    0           decoder_layer2_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual2 (Add)  (None, None, 256)    0           decoder_layer2_layernorm1[0][0]  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm2 (Laye (None, None, 256)    512         decoder_layer2_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_ffn1 (Dense)     (None, None, 256)    65792       decoder_layer2_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_ffn2 (Dense)     (None, None, 256)    65792       decoder_layer2_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 256)    0           decoder_layer2_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual3 (Add)  (None, None, 256)    0           decoder_layer2_layernorm2[0][0]  \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm3 (Laye (None, None, 256)    512         decoder_layer2_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_mha1 (MultiHeadA (None, None, 256)    65536       decoder_layer2_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 256)    0           decoder_layer3_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual1 (Add)  (None, None, 256)    0           decoder_layer2_layernorm3[0][0]  \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm1 (Laye (None, None, 256)    512         decoder_layer3_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_mha2 (MultiHeadA (None, None, 256)    65536       decoder_layer3_layernorm1[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 256)    0           decoder_layer3_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual2 (Add)  (None, None, 256)    0           decoder_layer3_layernorm1[0][0]  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm2 (Laye (None, None, 256)    512         decoder_layer3_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_ffn1 (Dense)     (None, None, 256)    65792       decoder_layer3_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_ffn2 (Dense)     (None, None, 256)    65792       decoder_layer3_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, None, 256)    0           decoder_layer3_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual3 (Add)  (None, None, 256)    0           decoder_layer3_layernorm2[0][0]  \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm3 (Laye (None, None, 256)    512         decoder_layer3_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_mha1 (MultiHeadA (None, None, 256)    65536       decoder_layer3_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, 256)    0           decoder_layer4_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual1 (Add)  (None, None, 256)    0           decoder_layer3_layernorm3[0][0]  \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm1 (Laye (None, None, 256)    512         decoder_layer4_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_mha2 (MultiHeadA (None, None, 256)    65536       decoder_layer4_layernorm1[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "                                                                 encoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, None, 256)    0           decoder_layer4_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual2 (Add)  (None, None, 256)    0           decoder_layer4_layernorm1[0][0]  \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm2 (Laye (None, None, 256)    512         decoder_layer4_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_ffn1 (Dense)     (None, None, 256)    65792       decoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_ffn2 (Dense)     (None, None, 256)    65792       decoder_layer4_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, None, 256)    0           decoder_layer4_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual3 (Add)  (None, None, 256)    0           decoder_layer4_layernorm2[0][0]  \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm3 (Laye (None, None, 256)    512         decoder_layer4_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "shared_weights_1 (SharedWeights (None, None, 10001)  0           decoder_layer4_layernorm3[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 4,409,600\n",
      "Trainable params: 4,409,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OPTS = tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "TARGET_PLACEHOLDER = tf.placeholder(dtype='int32', shape=(None, SENTENCE_LEN))\n",
    "model.compile(\n",
    "    loss=LOSS,\n",
    "    optimizer=OPTIMIZER,\n",
    "    metrics=METRICS,\n",
    "    target_tensors=[TARGET_PLACEHOLDER],\n",
    "#    options=RUN_OPTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity:    10001.00000000001\tentropy:    9.210440366976517\n",
      "perplexity:    8103.083927575384\tentropy:                    9\n",
      "perplexity:   2980.9579870417283\tentropy:                    8\n",
      "perplexity:   1096.6331584284585\tentropy:                    7\n",
      "perplexity:    403.4287934927351\tentropy:                    6\n",
      "perplexity:    148.4131591025766\tentropy:                    5\n",
      "perplexity:   54.598150033144236\tentropy:                    4\n",
      "perplexity:   20.085536923187668\tentropy:                    3\n",
      "perplexity:     7.38905609893065\tentropy:                    2\n",
      "perplexity:    2.718281828459045\tentropy:                    1\n",
      "perplexity:                  1.0\tentropy:                    0\n"
     ]
    }
   ],
   "source": [
    "# print loss values for reference\n",
    "def display_loss_reference():\n",
    "    format_ = 'perplexity: %20s\\tentropy: %20s'\n",
    "    upper_limit = np.log(VOCAB_SIZE)\n",
    "    print(format_ % (np.exp(upper_limit), upper_limit))\n",
    "    for i in reversed(range(int(np.floor(upper_limit))+1)):\n",
    "        print(format_ % (np.exp(i), i))\n",
    "display_loss_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    TRAIN_GEN,\n",
    "    steps_per_epoch=N_TRAIN_STEPS,\n",
    "    validation_data=TEST_GEN,\n",
    "    validation_steps=N_VALIDATION_STEPS,\n",
    "    callbacks=CALLBACKS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
