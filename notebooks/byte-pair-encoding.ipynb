{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the [sentencepiece](https://github.com/google/sentencepiece) Byte-Pair-Encoder with a nice API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN_SENTENCES = 10_000_000\n",
    "VOCAB_SIZE = 10_000\n",
    "MODEL_NAME = 'summarizer'\n",
    "TRAINING_FILE = f'summary_bpe_train_{VOCAB_SIZE}.txt'\n",
    "DATA_DIRECTORY = '../data/preprocessed_stories'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "FILES = glob.glob(os.path.join(DATA_DIRECTORY, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311971"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5cbc6f08ae45e3b73e810a10e4f21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=311971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Quit(Exception): pass\n",
    "try:\n",
    "    with open(TRAINING_FILE, 'w') as f_train:\n",
    "        n_sentences = 0\n",
    "        for file in tqdm(FILES):\n",
    "            with open(file) as f:\n",
    "                for line in f:\n",
    "                    n_sentences += 1\n",
    "                    if n_sentences == N_TRAIN_SENTENCES:\n",
    "                        raise Quit(\n",
    "                            'hacky solution to break from two for loops in '\n",
    "                            'notebook without defining a bunch of funtions and '\n",
    "                            'overengineering this whole thing.'\n",
    "                            'But then again 6 indents later...')\n",
    "                    f_train.write(line.replace('\\t', ' '))\n",
    "except Quit:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "\n",
    "class BytePairEncoder:\n",
    "    def __init__(self, vocab_size, model_name, *, model_file=None, vocab_file=None,\n",
    "                 training_file=None, processor=None, **kwargs):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model_name = f'{model_name}_{vocab_size}'\n",
    "        self.training_file = training_file\n",
    "        self.model_file = f'{self.model_name}.model' if model_file is None else model_file\n",
    "        self.vocab_file = f'{self.model_name}.vocab' if vocab_file is None else vocab_file\n",
    "        self.model_type = 'bpe'\n",
    "        if processor is None:\n",
    "            if training_file is None:\n",
    "                raise ValueError('training_file cannot be None when processor is also None.')\n",
    "            processor = self._fit(input=training_file, vocab_size=self.vocab_size,\n",
    "                                  model_prefix=self.model_name, model_type=self.model_type,\n",
    "                                  **kwargs)\n",
    "        self.processor = processor\n",
    "        \n",
    "    def encode(self, text):\n",
    "        return np.array(self.processor.EncodeAsIds(text))\n",
    "    \n",
    "    def encode_as_pieces(self, text):\n",
    "        return self.processor.EncodeAsPieces(text)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.processor.DecodeIds(ids.tolist())\n",
    "    \n",
    "    def decode_pieces(self, pieces):\n",
    "        return self.processor.DecodePieces(pieces)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, model_file, vocab_file):\n",
    "        model_name = model_file.partition('.')[0]\n",
    "        processor = cls._load_model(model_file)\n",
    "        for vocab_size, _ in enumerate(open(vocab_file), start=1): pass\n",
    "        return cls(vocab_size=vocab_size, model_name=model_name, processor=processor,\n",
    "                   model_file=model_file, vocab_file=vocab_file)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_model(filename):\n",
    "        processor = spm.SentencePieceProcessor()\n",
    "        processor.Load(filename)\n",
    "        return processor\n",
    "        \n",
    "    def _fit(self, **kwargs):\n",
    "        params = ' '.join([f'--{k}={v}' for k, v in kwargs.items()])\n",
    "        print(params)\n",
    "        spm.SentencePieceTrainer.Train(params)\n",
    "        processor = self._load_model(self.model_file)\n",
    "        return processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--input=summary_bpe_train_10000.txt --vocab_size=10000 --model_prefix=summarizer_10000 --model_type=bpe\n",
      "CPU times: user 2min 40s, sys: 40.2 s, total: 3min 20s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bpe = BytePairEncoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    model_name=MODEL_NAME,\n",
    "    training_file=TRAINING_FILE, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summarizer_10000'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"While the firelight's aglow strange shadows in the flames will grow till things we've never seen will seem familiar\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = ' '.join('''\n",
    "While the firelight's aglow\n",
    "strange shadows in the flames will grow\n",
    "till things we've never seen\n",
    "will seem familiar\n",
    "'''.strip().split('\\n'))\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2232,    8, 1247, 3551, 9948, 9930,  262, 7425, 7730,  151,   62,\n",
       "       2173,   30,    8, 8435,  239, 1697,    3,   96, 1519,  166, 9948,\n",
       "         54,  925,  941,  239, 1473, 7337])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = bpe.encode(sample_text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"While the firelight's aglow strange shadows in the flames will grow till things we've never seen will seem familiar\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xe2\\x96\\x81While',\n",
       " b'\\xe2\\x96\\x81the',\n",
       " b'\\xe2\\x96\\x81fire',\n",
       " b'light',\n",
       " b\"'\",\n",
       " b's',\n",
       " b'\\xe2\\x96\\x81ag',\n",
       " b'low',\n",
       " b'\\xe2\\x96\\x81strange',\n",
       " b'\\xe2\\x96\\x81sh',\n",
       " b'ad',\n",
       " b'ows',\n",
       " b'\\xe2\\x96\\x81in',\n",
       " b'\\xe2\\x96\\x81the',\n",
       " b'\\xe2\\x96\\x81flames',\n",
       " b'\\xe2\\x96\\x81will',\n",
       " b'\\xe2\\x96\\x81grow',\n",
       " b'\\xe2\\x96\\x81t',\n",
       " b'ill',\n",
       " b'\\xe2\\x96\\x81things',\n",
       " b'\\xe2\\x96\\x81we',\n",
       " b\"'\",\n",
       " b've',\n",
       " b'\\xe2\\x96\\x81never',\n",
       " b'\\xe2\\x96\\x81seen',\n",
       " b'\\xe2\\x96\\x81will',\n",
       " b'\\xe2\\x96\\x81seem',\n",
       " b'\\xe2\\x96\\x81familiar']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = bpe.encode_as_pieces(sample_text)\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"While the firelight's aglow strange shadows in the flames will grow till things we've never seen will seem familiar\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.decode_pieces(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" While the firelight's aglow strange shadows in the flames will grow till things we've never seen will seem familiar\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(p.decode('utf-8').replace('▁', ' ') for p in pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'cnn.vocab' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 cnn.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: cannot open 'cnn.vocab' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 cnn.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = BytePairEncoder.from_files('summarizer.model', 'summarizer.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xe2\\x96\\x81While',\n",
       " b'\\xe2\\x96\\x81the',\n",
       " b'\\xe2\\x96\\x81fire',\n",
       " b'light',\n",
       " b\"'\",\n",
       " b's',\n",
       " b'\\xe2\\x96\\x81ag',\n",
       " b'low',\n",
       " b'\\xe2\\x96\\x81strange',\n",
       " b'\\xe2\\x96\\x81sh',\n",
       " b'ad',\n",
       " b'ows',\n",
       " b'\\xe2\\x96\\x81in',\n",
       " b'\\xe2\\x96\\x81the',\n",
       " b'\\xe2\\x96\\x81flames',\n",
       " b'\\xe2\\x96\\x81will',\n",
       " b'\\xe2\\x96\\x81grow',\n",
       " b'\\xe2\\x96\\x81t',\n",
       " b'ill',\n",
       " b'\\xe2\\x96\\x81things',\n",
       " b'\\xe2\\x96\\x81we',\n",
       " b\"'\",\n",
       " b've',\n",
       " b'\\xe2\\x96\\x81never',\n",
       " b'\\xe2\\x96\\x81seen',\n",
       " b'\\xe2\\x96\\x81will',\n",
       " b'\\xe2\\x96\\x81seem',\n",
       " b'\\xe2\\x96\\x81familiar']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = bpe.encode_as_pieces(sample_text)\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 'summarizer_10000')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.vocab_size, bpe.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
